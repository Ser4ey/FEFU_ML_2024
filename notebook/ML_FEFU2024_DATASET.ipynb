{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Подготовка датасета\n"
      ],
      "metadata": {
        "id": "b5Mm07dgzEcS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импортируем необходимые библиотеки"
      ],
      "metadata": {
        "id": "1zBZG8w68CWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
      ],
      "metadata": {
        "id": "UdVCrUk78BnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Преобразование из png 278 на 278 в jpg 28 на 28"
      ],
      "metadata": {
        "id": "nDE2UivAX0Su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Этот код преобразует все изображения в папке из png 278 на 278 в jpg 28 на 28\n",
        "\n",
        "# преобразуем изображение в jpg 28 на 28\n",
        "def convert_img(path):\n",
        "    png_image = Image.open(path)\n",
        "\n",
        "    # Создаем новое пустое изображение с белым фоном такого же размера\n",
        "    white_background = Image.new('RGB', png_image.size, (255, 255, 255))\n",
        "\n",
        "    # Копируем исходное изображение на новое изображение с белым фоном\n",
        "    white_background.paste(png_image, (0, 0), png_image)\n",
        "\n",
        "    # делаем изображение 28 на 28\n",
        "    new_image = white_background.resize((28, 28))\n",
        "\n",
        "    # Преобразуем изображение в черно-белое\n",
        "    new_image = new_image.convert('L')\n",
        "\n",
        "    # Сохраняем новое изображение в формате JPEG\n",
        "    new_image.save(path[:-4]+\".jpg\", 'JPEG')\n",
        "\n",
        "    # удаляем старое\n",
        "    os.remove(path)\n",
        "\n",
        "\n",
        "# преобразуем все изображения в папке с датасетом\n",
        "def normalize_images(input_dir):\n",
        "    # Перебираем все файлы в директории\n",
        "    print(input_dir)\n",
        "    entries = os.listdir(input_dir)\n",
        "\n",
        "    # Разделяем файлы и папки\n",
        "    files = [entry for entry in entries if os.path.isfile(os.path.join(input_dir, entry))]\n",
        "    folders = [entry for entry in entries if os.path.isdir(os.path.join(input_dir, entry))]\n",
        "\n",
        "    for i in files:\n",
        "        path = os.path.join(input_dir, i)\n",
        "        convert_img(path)\n",
        "\n",
        "    for i in folders:\n",
        "        path = os.path.join(input_dir, i)\n",
        "        normalize_images(path)\n",
        "\n",
        "\n",
        "# Указываем директории датасета\n",
        "input_dir = r'C:\\Users\\Sergey\\PycharmProjects\\FEFU_ML_2024\\Cyrillic'\n",
        "\n",
        "normalize_images(input_dir)\n"
      ],
      "metadata": {
        "id": "NyC9rXYrzQe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Балансировка датасета с последующим разделением датасета на тренировочный, валидационный и тестовый наборы\n"
      ],
      "metadata": {
        "id": "hbR38NJuX-C2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {}\n",
        "\n",
        "\n",
        "def get_images_paths(input_dir, folder=\"\"):\n",
        "    # Перебираем все файлы в директории\n",
        "    print(input_dir)\n",
        "    entries = os.listdir(input_dir)\n",
        "\n",
        "    # Разделяем файлы и папки\n",
        "    files = [entry for entry in entries if os.path.isfile(os.path.join(input_dir, entry))]\n",
        "    folders = [entry for entry in entries if os.path.isdir(os.path.join(input_dir, entry))]\n",
        "\n",
        "    for i in files:\n",
        "        path = os.path.join(input_dir, i)\n",
        "        dataset.setdefault(folder, [])\n",
        "        dataset[folder].append(path)\n",
        "\n",
        "    for i in folders:\n",
        "        path = os.path.join(input_dir, i)\n",
        "        get_images_paths(path, i)\n",
        "\n",
        "\n",
        "# Указываем директории с исходными и выходными изображениями\n",
        "input_dir = r'C:\\Users\\Sergey\\PycharmProjects\\FEFU_ML_2024\\Cyrillic'\n",
        "output_dir = r'C:\\Users\\Sergey\\PycharmProjects\\FEFU_ML_2024'\n",
        "\n",
        "output_dir_train_validation = os.path.join(output_dir, 'Cyrillic_Train_Validation')\n",
        "output_dir_test = os.path.join(output_dir, 'Cyrillic_Test')\n",
        "\n",
        "get_images_paths(input_dir)\n",
        "\n",
        "for k in dataset.keys():\n",
        "    print(k, len(dataset[k]))\n",
        "\n",
        "min_count = [len(i) for i in dataset.values()]\n",
        "min_count = min(min_count)\n",
        "print(\"min_count:\", min_count)\n",
        "\n",
        "\n",
        "for key in dataset.keys():\n",
        "    print(key)\n",
        "    value = dataset[key]\n",
        "    random.shuffle(value)\n",
        "\n",
        "    train_validation_dataset_path = os.path.join(output_dir_train_validation, key)\n",
        "    if not os.path.exists(train_validation_dataset_path):\n",
        "        # Создаем директорию, если нет\n",
        "        os.makedirs(train_validation_dataset_path)\n",
        "\n",
        "    test_dataset_path = os.path.join(output_dir_test, key)\n",
        "    if not os.path.exists(test_dataset_path):\n",
        "        # Создаем директорию, если нет\n",
        "        os.makedirs(test_dataset_path)\n",
        "\n",
        "    for i in value[:30]:\n",
        "        shutil.copy2(i, test_dataset_path)\n",
        "\n",
        "    for j in value[30:min_count]:\n",
        "        shutil.copy2(j, train_validation_dataset_path)\n"
      ],
      "metadata": {
        "id": "sIoOiWBuz3SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Аугментацией датасета\n",
        "\n",
        "Аугментация датасета играет важную роль в задачах машинного обучения, особенно в задачах, где данных недостаточно для обучения модели. Она позволяет увеличить размер датасета путем создания новых данных, основываясь на уже имеющихся."
      ],
      "metadata": {
        "id": "tu7ZRUTcY_9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# увеличиваем датасет\n",
        "\n",
        "def gen_variations(path_to_image, path_to_save_dir, number_of_variations=20):\n",
        "    datagen = ImageDataGenerator(\n",
        "            rotation_range=40,\n",
        "            width_shift_range=0.1,\n",
        "            height_shift_range=0.1,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=False,\n",
        "            fill_mode='nearest')\n",
        "\n",
        "    img = load_img(path_to_image)\n",
        "    x = img_to_array(img)\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "\n",
        "    i = 0\n",
        "    for batch in datagen.flow(x, batch_size=1,\n",
        "                              save_to_dir=path_to_save_dir,\n",
        "                              save_prefix=f'gen_{str(time.time())}',\n",
        "                              save_format='jpg'):\n",
        "        i += 1\n",
        "        if i > number_of_variations:\n",
        "            break\n",
        "\n",
        "\n",
        "files_and_folders = []\n",
        "def get_images_paths(input_dir):\n",
        "    # Перебираем все файлы в директории\n",
        "    print(input_dir)\n",
        "    entries = os.listdir(input_dir)\n",
        "\n",
        "    # Разделяем файлы и папки\n",
        "    files = [entry for entry in entries if os.path.isfile(os.path.join(input_dir, entry))]\n",
        "    folders = [entry for entry in entries if os.path.isdir(os.path.join(input_dir, entry))]\n",
        "\n",
        "    for i in files:\n",
        "        path = os.path.join(input_dir, i)\n",
        "        files_and_folders.append(\n",
        "            (path, input_dir)\n",
        "        )\n",
        "\n",
        "    for i in folders:\n",
        "        path = os.path.join(input_dir, i)\n",
        "        get_images_paths(path)\n",
        "\n",
        "\n",
        "input_dir = r'C:\\Users\\Sergey\\PycharmProjects\\FEFU_ML_2024\\Cyrillic'\n",
        "get_images_paths(input_dir)\n",
        "\n",
        "\n",
        "for i in range(len(files_and_folders)):\n",
        "    print(f\"{i+1}/{len(files_and_folders)}\")\n",
        "    gen_variations(files_and_folders[i][0], files_and_folders[i][1])\n"
      ],
      "metadata": {
        "id": "p-I-Gt7s0gKg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}